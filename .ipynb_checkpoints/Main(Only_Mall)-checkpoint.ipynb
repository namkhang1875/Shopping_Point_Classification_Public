{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import tree\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# car_df is the dataframe load from veh_tx\n",
    "# df is the car_df dataframe that already group by, calculate the parking duration and assign shopping_point\n",
    "########################################################\n",
    "\n",
    "#################################################### STEP 1: Load Dataset #####################################################################\n",
    "\n",
    "car_df1 = pd.read_csv('G:\\\\My Drive\\\\ITS_DA\\\\veh_tx_data\\\\2019-11-10_15.zip', compression='zip')\n",
    "car_df2 = pd.read_csv('G:\\\\My Drive\\\\ITS_DA\\\\veh_tx_data\\\\2019-11-10_18.zip', compression='zip')\n",
    "\n",
    "#############################################################################################################################################\n",
    "\n",
    "#################################################### STEP 1.5: Data Processing ##############################################################\n",
    "# car_df1.isna().sum()\n",
    "# car_df2.isna().sum()\n",
    "car_df1.dropna(inplace=True)\n",
    "car_df2.dropna(inplace=True)\n",
    "\n",
    "car_df = pd.concat([car_df1,car_df2])\n",
    "# print(car_df.isna().sum())\n",
    "\n",
    "# print(car_df.info())\n",
    "# print(car_df.head(50))\n",
    "# print(shopping_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Time Elpased to detemine that which point is a shopping point\n",
    "car_df[\"time_stamp\"] = pd.to_datetime(car_df[\"time_stamp\"])\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "# Round Latitude Longitude to 1 digit float\n",
    "car_df[\"latx\"] = round(car_df[\"lat\"], 1)\n",
    "car_df[\"lonx\"] = round(car_df[\"lon\"], 1)\n",
    "\n",
    "# Round Latitude Longitude to 2 digit float\n",
    "car_df[\"latxx\"] = round(car_df[\"lat\"], 2)\n",
    "car_df[\"lonxx\"] = round(car_df[\"lon\"], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the value to calculate the duration of parking\n",
    "test = car_df[car_df['speed'] == 0].groupby(['vid','latxx','lonxx','unit_type'])['time_stamp'].min()  # first time_stamp \n",
    "test2 = car_df[car_df['speed'] == 0].groupby(['vid','latxx','lonxx','unit_type'])['time_stamp'].max() # last time_stamp\n",
    "ans = test2-test\n",
    "\n",
    "df1 = pd.DataFrame(data=ans.index, columns=['vid'])\n",
    "df2 = pd.DataFrame(data=ans.values, columns=['duration'])\n",
    "df = pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df[\"parking\"] = \"\"\n",
    "df[\"parking\"] = \"\"\n",
    "df[\"latxx\"] = \"\"\n",
    "df[\"lonxx\"] = \"\"\n",
    "df[\"unit_type\"] = \"\"\n",
    "df[['vid', 'latxx' ,'lonxx','unit_type']] = pd.DataFrame(df['vid'].tolist(),index=df.index)\n",
    "# print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# filter others province ############################## \n",
    "\n",
    "df.drop(df[(df.latxx < 18.72) | (df.lonxx <98.94)].index , inplace = True)\n",
    "df.drop(df[(df.latxx > 18.87) | (df.lonxx >99.06)].index , inplace = True)\n",
    "\n",
    "# print(df.head(30))\n",
    "\n",
    "############################ So now it has only points in Chiang Mai ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Loop to calculate the duration of parking #################################\n",
    "################ If it's a parking point then the column \"parking\" will be 1,  if not then will be 0 #####################\n",
    "list = []\n",
    "for row in df.itertuples():\n",
    "    time_stamp = row.duration\n",
    "    \n",
    "    seconds = time_stamp.seconds\n",
    "    hours = seconds//3600\n",
    "    minutes = (seconds//60) % 60\n",
    "\n",
    "    # print(\"minute = \", minutes)\n",
    "    # print(\"hours  = \", hours)\n",
    "    # print(\" \")\n",
    "\n",
    "    vid = row.vid\n",
    "    latx = row.latxx\n",
    "    lonx = row.lonxx\n",
    "    \n",
    "    indicator = 0\n",
    "\n",
    "    if (minutes >= 30 and hours < 1) or (hours >= 1 and hours < 2) or (hours >= 2 and minutes <= 30):  # 2 hours and half\n",
    "        indicator =1\n",
    "    else:\n",
    "        indicator =0\n",
    "       \n",
    "    list.append(indicator)\n",
    "    \n",
    "df['parking'] = list #assign parking indicator to dataframe\n",
    "\n",
    "\n",
    "\n",
    "# ตอนนี้ได้จุดจอดแล้ว เหลือนำไปสร้าง feature\n",
    "# แล้วก็กรองให้เหลือแต่เชียงใหม่แล้ว\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Load Dataset of Shopping Point ###############################\n",
    "shopping_df = pd.read_csv(\n",
    "    'C:\\\\Users\\\\Fantasticboy\\\\Documents\\\\GitHub\\\\Shopping_Point_Classification\\\\shoppingCenter2.csv')\n",
    "# print(shopping_df.head(30))\n",
    "\n",
    "df['shopping_point'] = \"\"\n",
    "shopping_list = []\n",
    "indicator2 = 0\n",
    "shopping_len = len(shopping_df['latxx'])\n",
    "iterator = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Compare coordinate of the dataframe and coordiante of the shopping point to assign the shopping point to column \"Shopping\" ##############\n",
    "\n",
    "for row in df.itertuples():\n",
    "    dflatxx = row.latxx\n",
    "    dflonxx = row.lonxx\n",
    "    dfunit_type = row.unit_type\n",
    "    dfparking = row.parking\n",
    "    for a,b in zip(shopping_df.latxx, shopping_df.lonxx):\n",
    "        if dflatxx == a and dflonxx == b :\n",
    "            shopping_list.append(1)\n",
    "            iterator = 0\n",
    "            break\n",
    "        \n",
    "        iterator +=1\n",
    "        if iterator == shopping_len:\n",
    "            shopping_list.append(0)\n",
    "        \n",
    "    iterator = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# If the length of 2 dataframe is not match then fill by 0 #################\n",
    "df['shopping_point'] = shopping_list\n",
    "# print(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "df['is_has_a_lot_of_cars'] = \"\"\n",
    "# temp_df['number_of_cars'] = \"\"\n",
    "# temp_df = df.groupby(['latxx','lonxx'])\n",
    "temp = df[df['parking'] == 1].groupby(['latxx','lonxx'])['vid'].count()\n",
    "temp_df1 = pd.DataFrame(data=temp.values, columns=['count'])\n",
    "temp_df2 = pd.DataFrame(data=temp.index, columns=['latxx_lonxx'])\n",
    "temp_df = pd.merge(temp_df1,temp_df2, left_index=True, right_index=True)\n",
    "# temp_df = df[['vid','parking','latxx','lonxx']]\n",
    "# print(temp_df1.head())\n",
    "# print(temp_df2.head())\n",
    "# print(temp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################### Calculate the point that has a lot of cars ###########################\n",
    "df['is_has_a_lot_of_cars'] = \"\"\n",
    "# temp_df['number_of_cars'] = \"\"\n",
    "# temp_df = df.groupby(['latxx','lonxx'])\n",
    "temp = df[df['parking'] == 1].groupby(['latxx','lonxx'])['vid'].count()\n",
    "temp_df1 = pd.DataFrame(data=temp.values, columns=['count'])\n",
    "temp_df2 = pd.DataFrame(data=temp.index, columns=['latxx_lonxx'])\n",
    "temp_df = pd.merge(temp_df1,temp_df2, left_index=True, right_index=True)\n",
    "# temp_df = df[['vid','parking','latxx','lonxx']]\n",
    "# print(temp_df1.head())\n",
    "# print(temp_df2.head())\n",
    "# print(temp_df.head())\n",
    "\n",
    "\n",
    "temp_df[\"latxx\"] = \"\"\n",
    "temp_df[\"lonxx\"] = \"\"\n",
    "\n",
    "temp_df[[ 'latxx' ,'lonxx']] = pd.DataFrame(temp_df['latxx_lonxx'].tolist(),index=temp_df.index)\n",
    "# df[['vid', 'latxx' ,'lonxx','unit_type']] = pd.DataFrame(df['vid'].tolist(),index=df.index)\n",
    "# print(temp_df.head(10))\n",
    "\n",
    "iterator2 = 0\n",
    "tempdf_len = len(temp_df['latxx'])\n",
    "\n",
    "for a,b in zip(df.latxx, df.lonxx):\n",
    "    \n",
    "    for row in temp_df.itertuples():\n",
    "        count=row.count\n",
    "        temp_latxx = row.latxx\n",
    "        temp_lonxx = row.lonxx\n",
    "            \n",
    "        if temp_latxx == a and temp_lonxx == b:\n",
    "            if count >=15:\n",
    "                # df[(df['latxx'] == a) & (df['lonxx'] == b)]['is_has_a_lot_of_cars'] = 1\n",
    "                df.loc[(df['latxx'] == a) & (df['lonxx'] == b), 'is_has_a_lot_of_cars'] = 1\n",
    "                iterator2 = 0\n",
    "                break\n",
    "            \n",
    "        iterator2 +=1\n",
    "        if iterator2 == tempdf_len:\n",
    "            # df[(df['latxx'] == a) & (df['lonxx'] == b)]['is_has_a_lot_of_cars'] = 0\n",
    "            df.loc[(df['latxx'] == a) & (df['lonxx'] == b), 'is_has_a_lot_of_cars'] = 0\n",
    "            iterator2 = 0\n",
    "\n",
    "# print(df.head(20))\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=\"shopping_point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"parking\", hue=\"shopping_point\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"unit_type\", hue=\"shopping_point\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"is_has_a_lot_of_cars\", hue=\"shopping_point\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"shopping_point\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('shopping_point').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().sort_values(\"shopping_point\")[\"shopping_point\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, x_vars=['parking','unit_type','is_has_a_lot_of_cars'], y_vars=['shopping_point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Feature Selection ###################################\n",
    "X = df[['parking','unit_type','is_has_a_lot_of_cars']]\n",
    "Y = df['shopping_point']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Split the train and test dataset ########################\n",
    "# print(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=101)\n",
    "\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################## Build a model ####################################\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "# # clf = LogisticRegression()\n",
    "# # clf.fit(X, Y)\n",
    "\n",
    "# # clf = tree.DecisionTreeClassifier()\n",
    "# # clf.fit(X, Y)\n",
    "\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf.fit(X_train, Y_train)\n",
    "\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(X_train,Y_train)\n",
    "\n",
    "# # clf = svm.SVC()\n",
    "# # clf.fit(X, Y)\n",
    "\n",
    "# clf = KNeighborsClassifier(n_neighbors=5)\n",
    "# clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Predict #####################\n",
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Report #####################\n",
    "print(\"*********Confusion Matrix*********\")\n",
    "cm_labels = df['shopping_point'].unique()\n",
    "print(cm_labels)\n",
    "print(confusion_matrix(Y_test, Y_pred, labels = cm_labels))\n",
    "\n",
    "print(\"**************Report**************\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print(\"************* F1 ***************\")\n",
    "f1 = f1_score(Y_test, Y_pred, average = 'weighted')\n",
    "print('F1 = ', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
